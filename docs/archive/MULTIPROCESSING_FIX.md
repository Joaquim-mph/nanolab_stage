# Multiprocessing Deadlock Fix

## Problem

When running the full pipeline command, the process would freeze at the beginning of Stage 2 (preprocessing):

```
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Stage 2: Staged Parquet ‚Üí Segments ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

INFO     Scanning for IV runs in data/02_stage/raw_measurements...
INFO     Found 7,636 IV runs

‚†º Processing IV runs... ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ   0%    0/7636 -:--:-- 0:00:38
[FROZEN HERE]
```

However:
- Running `stage` command alone: ‚úÖ Works
- Running `preprocess` command alone: ‚úÖ Works
- Running `pipeline` command (both together): ‚ùå Freezes

## Root Cause

**ProcessPoolExecutor cleanup conflict** between consecutive stages.

When using Python's `ProcessPoolExecutor` with `with` statement:
```python
with ProcessPoolExecutor(max_workers=8) as executor:
    # Stage 1 processing
    ...

# Stage 2 starts
with ProcessPoolExecutor(max_workers=8) as executor:
    # This can deadlock!
    ...
```

The problem:
1. Stage 1's `ProcessPoolExecutor` finishes and exits the context manager
2. Python's context manager calls `executor.shutdown(wait=True)` automatically
3. However, worker processes might not be fully terminated yet
4. Stage 2 immediately tries to create a new `ProcessPoolExecutor`
5. **Deadlock:** New executor can't spawn workers while old ones are still cleaning up

This is especially problematic when:
- Processing large numbers of files (31,806 CSVs in this case)
- Using 8+ workers
- Running stages back-to-back without delay

## Solution

### 1. Explicit Executor Cleanup

Changed from nested `with` statements to explicit shutdown:

**Before (problematic):**
```python
with progress:
    with ProcessPoolExecutor(max_workers=params.workers) as executor:
        # Process files
        ...
```

**After (fixed):**
```python
executor = ProcessPoolExecutor(max_workers=params.workers)

try:
    with progress:
        # Submit all tasks
        futures = {}
        for item in items:
            future = executor.submit(process_func, item)
            futures[future] = item

        # Process results
        for future in as_completed(futures):
            result = future.result()
            # Handle result
            ...
finally:
    # Explicit shutdown with wait
    executor.shutdown(wait=True)
    del executor  # Force garbage collection
```

This ensures:
- Executor is fully shutdown before exiting the function
- All worker processes are terminated
- Memory is properly cleaned up with `del`

### 2. Garbage Collection Between Stages

Added explicit cleanup between Stage 1 and Stage 2:

```python
# Stage 1 completes
...

# ========== CLEANUP BETWEEN STAGES ==========
gc.collect()  # Force garbage collection
time.sleep(0.5)  # Small delay for cleanup

# Stage 2 starts
...
```

This ensures:
- Python garbage collector runs immediately
- Any remaining references are cleaned up
- Worker processes have time to fully terminate
- New executor starts with clean state

### 3. Files Modified

#### `src/cli/utils/staging_wrapper.py`
```python
# Line 86-135
executor = ProcessPoolExecutor(max_workers=params.workers)

try:
    with progress:
        # ... processing ...
finally:
    executor.shutdown(wait=True)
    del executor
```

#### `src/cli/utils/preprocessing_wrapper.py`
```python
# Line 181-232
executor = ProcessPoolExecutor(max_workers=params.workers)

try:
    with progress:
        # ... processing ...
finally:
    executor.shutdown(wait=True)
    del executor
```

#### `src/cli/commands/pipeline.py`
```python
# Line 9: Import gc
import gc

# Line 335-338: Cleanup between stages
gc.collect()
time.sleep(0.5)
```

## Why This Works

1. **Explicit shutdown:** Ensures executor waits for all workers to finish
2. **Delete reference:** Forces Python to clean up executor object immediately
3. **Garbage collection:** Ensures all related objects are cleaned up
4. **Time delay:** Gives OS time to fully terminate worker processes
5. **Clean state:** Stage 2 starts with no lingering processes

## Testing

### Individual Commands (Already Worked)
```bash
# Stage only - Works ‚úÖ
python nanolab-pipeline.py stage --raw-root data/01_raw --stage-root data/02_stage

# Preprocess only - Works ‚úÖ
python nanolab-pipeline.py preprocess --stage-root data/02_stage --output-root data/03_intermediate
```

### Pipeline Command (Now Fixed)
```bash
# Full pipeline - Now works ‚úÖ
python nanolab-pipeline.py pipeline \
  --raw-root data/01_raw \
  --stage-root data/02_stage/raw_measurements \
  --output-root data/03_intermediate \
  --workers 8
```

Expected output:
```
Stage 1: Raw CSV ‚Üí Staged Parquet
  [Progress bar]
  ‚úì Stage 1 complete: 30,500 files staged

[0.5s cleanup delay]

Stage 2: Staged Parquet ‚Üí Segments
  [Progress bar]
  ‚úì Stage 2 complete: 7,636 runs, 30,544 segments

Pipeline Complete
  Timeline, Summary, Success message
```

## Performance Impact

The 0.5 second delay between stages is negligible:
- Stage 1: ~2-5 minutes (30,000+ files)
- Cleanup: 0.5 seconds
- Stage 2: ~30-60 seconds (7,000+ runs)
- **Total overhead: <0.5% of pipeline time**

## Best Practices

When using `ProcessPoolExecutor` in sequential stages:

‚úÖ **Do:**
- Use explicit `shutdown(wait=True)`
- Delete executor reference with `del`
- Add garbage collection between stages
- Include small delay for cleanup
- Use try/finally for cleanup

‚ùå **Don't:**
- Rely on `with` context manager alone
- Start new executor immediately after old one
- Assume workers are cleaned up instantly
- Skip garbage collection between stages

## Alternative Solutions Considered

### 1. Use `multiprocessing.Pool` instead
- **Pros:** More explicit control
- **Cons:** Less Pythonic, more boilerplate
- **Decision:** Stick with `ProcessPoolExecutor` for consistency

### 2. Reuse same executor for both stages
- **Pros:** No cleanup needed
- **Cons:** Can't change worker count, state pollution
- **Decision:** Keep stages independent

### 3. Use threading instead of multiprocessing
- **Pros:** No process cleanup issues
- **Cons:** GIL limits performance for CPU-bound tasks
- **Decision:** Multiprocessing needed for Polars/CPU work

## Conclusion

The fix ensures proper cleanup of `ProcessPoolExecutor` between stages by:
1. Explicit shutdown with wait
2. Forced garbage collection
3. Small cleanup delay
4. Delete executor reference

This resolves the deadlock while maintaining:
- ‚úÖ Clean code structure
- ‚úÖ Full performance
- ‚úÖ Minimal overhead (<0.5%)
- ‚úÖ Reliable execution

The pipeline command now works seamlessly with thousands of files! üöÄ
